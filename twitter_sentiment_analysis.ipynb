{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1c1b61",
   "metadata": {},
   "source": [
    "# 🎯 Projenin Amacı\n",
    "\n",
    "Bu çalışmanın temel amacı, sosyal medya platformlarından biri olan Twitter üzerinde paylaşılan gönderiler aracılığıyla kullanıcıların duygu durumlarını sınıflandırmaktır. Doğal dil işleme (NLP) teknikleri ve makine öğrenmesi algoritmaları kullanılarak, tweet metinleri üzerinden otomatik duygu analizi gerçekleştirilmiştir. Bu analiz sonucunda, her bir tweet’in olumlu (positive), olumsuz (negative) veya nötr (neutral) olarak sınıflandırılması hedeflenmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153f795",
   "metadata": {},
   "source": [
    "### 📦 1. Gerekli Kütüphanelerin Yüklenmesi ve Verinin İçeri Aktarılması\n",
    "\n",
    "Bu bölümde, proje için gerekli olan Python kütüphaneleri yüklenir ve CSV dosyasından veri seti içeri alınır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed51808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Veriyi yükle\n",
    "data = pd.read_csv(\"twitter.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4e2b8",
   "metadata": {},
   "source": [
    "### 🧽 2. Metin Temizleme İşlemleri\n",
    "\n",
    "Bu bölümde, tweet metinleri temizlenerek makine öğrenmesi için daha uygun hale getirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64662207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AhmetD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "# Temizleme işlemini uygulama\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779d05d",
   "metadata": {},
   "source": [
    "### 🧠 3. Duygu Analizi Skorlarının Hesaplanması\n",
    "\n",
    "Tweet'ler üzerinden pozitif, negatif ve nötr duygu skorları hesaplanır ve veri setine eklenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1e6188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\AhmetD\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
    "data[\"Neutral\"]  = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"tweet\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375dcc1",
   "metadata": {},
   "source": [
    "### 🧾 4. Kullanılacak Sütunların Seçilmesi\n",
    "\n",
    "Yalnızca analiz için gerekli sütunlar (tweet, pozitif, negatif, nötr) tutulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3ba71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  Positive  Negative  \\\n",
      "0   rt mayasolov woman shouldnt complain clean ho...     0.147     0.157   \n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...     0.000     0.280   \n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...     0.000     0.577   \n",
      "3             rt cganderson vivabas look like tranni     0.333     0.000   \n",
      "4   rt shenikarobert shit hear might true might f...     0.154     0.407   \n",
      "\n",
      "   Neutral  \n",
      "0    0.696  \n",
      "1    0.720  \n",
      "2    0.423  \n",
      "3    0.667  \n",
      "4    0.440  \n"
     ]
    }
   ],
   "source": [
    "data = data[[\"tweet\", \"Positive\", \"Negative\", \"Neutral\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c8da2",
   "metadata": {},
   "source": [
    "### 📊 5. Genel Duygu Durumunun Belirlenmesi\n",
    "\n",
    "Tüm tweet'ler için toplam duygu puanları hesaplanır ve hangi duygu öne çıkıyorsa o duygu durumunu temsil eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0935a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral 🙂 \n"
     ]
    }
   ],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a > b) and (a > c):\n",
    "        print(\"Positive 😊 \")\n",
    "    elif (b > a) and (b > c):\n",
    "        print(\"Negative 😠 \")\n",
    "    else:\n",
    "        print(\"Neutral 🙂 \")\n",
    "\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f6ada",
   "metadata": {},
   "source": [
    "### 📈 6. Duygu Skorlarının Sayısal Olarak Görüntülenmesi\n",
    "\n",
    "Toplam pozitif, negatif ve nötr duygu puanları terminale yazdırılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5da371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  2880.086000000009\n",
      "Negative:  7201.020999999922\n",
      "Neutral:  14696.887999999733\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive: \", x)\n",
    "print(\"Negative: \", y)\n",
    "print(\"Neutral: \", z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
